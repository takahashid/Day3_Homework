{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day4概要および結論\n",
    "- 前回、きのこデータをRandom Forestで分類した際、Score=1.0になりました。\n",
    "- 今回、きのこデータをSVMで分類したところやはり容易にScore=1.0になりました。\n",
    "- \n",
    "- データが簡単で分類しやすいためかと思いtrain_test_splitの比率を変え、訓練データを減らしたときの挙動を見ました。\n",
    "- →　訓練データ数が1000個程度を下回るくらいから、Scoreが悪くなることがわかりました。\n",
    "- →→　データ数は、もともと8000個程度あるので、十分な量があることがわかりました。\n",
    "- →→　また、2値分類の問題（食べれるか否か）であって、かつ、説明変数が120個ほどある、\n",
    "- →→　データに誤りや異常値がない(と思われる)ことから、やはり比較的分類しやすいデータなのかなと思いました。\n",
    "- \n",
    "- またRandom Forestのfeature_importanceが高い説明変数、低い説明変数を使ったときの挙動を見ました。\n",
    "- →　高いほうのみ20個の説明変数を使った場合は、最大Score=1.00、\n",
    "- →　高いほうのみ10個の説明変数を使った場合は、最大Score=0.98程度、\n",
    "- →　低いほうのみ10個の説明変数を使った場合は、最大Score=0.6 程度、となりました。\n",
    "- →　importanceが、分類精度に寄与していることががわかりました。\n",
    "- →　説明変数を減らしても高い汎化性能がでるのであれば、人間にとっての理解性が高いのでがよいと思いました。（説明変数の選択はなんらか機械的に選択したいところ）\n",
    "- →　説明変数を117個すべて使うと、Score=1.0となりますがマルチコの影響が出ていないように見え、解析まで至っていません。\n",
    "- \n",
    "- SVM linear, SVM rbf, Random Forest, Logistic Regressionの４つを使ったときの違いを見ました。\n",
    "- →　高いほうのみ5個の説明変数を使った場合に、\n",
    "- →　SVM linear：0.995以上、 \n",
    "- →　SVM rbf、Random Forest、Logistic Regression：0.965程度\n",
    "- →　と、若干の差(0.03ほど)がでました。(計算する毎にぶれますが。。。)理由として以下２点があると考えています。\n",
    "- →　①SVMのマージン最大化のおかげ、②きのこデータが線形分離可能な可能性がありrbfは適さない。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split , GridSearchCV # Data分割, Parameter tuning,\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['class', 'cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor',\n",
      "       'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color',\n",
      "       'stalk-shape', 'stalk-root', 'stalk-surface-above-ring',\n",
      "       'stalk-surface-below-ring', 'stalk-color-above-ring',\n",
      "       'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number',\n",
      "       'ring-type', 'spore-print-color', 'population', 'habitat'],\n",
      "      dtype='object')\n",
      "shape:(8124, 23)\n"
     ]
    }
   ],
   "source": [
    "# データ取り込み\n",
    "dfm = pd.read_csv(\"mushrooms/mushrooms.csv\")\n",
    "#　きのこの属性表示。目的変数：class edible or poisonous 2値, 説明変数：22種。\n",
    "print(dfm.columns)\n",
    "print(\"shape:\"+ str(dfm.shape))\n",
    "#dfm.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8124, 23)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  すべてカテゴリ変数なので、ダミー変数にする\n",
    "dfm_d = pd.get_dummies(dfm)\n",
    "dfm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練データ数を変える"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train data, test dataを作る。\n",
    "y = dfm_d.class_p.to_frame()\n",
    "X = dfm_d.drop([\"class_p\",\"class_e\"], axis=1)\n",
    "\n",
    "## test_train_split用変数\n",
    "test_size_list = [0.2,0.5,0.9,0.93,0.96,0.98,0.99,0.999]\n",
    "test_split_num = 1 # ひとまず１回にする。複数回計算しその平均を取る予定だったが未実装。\n",
    "\n",
    "## 解析用保存パラメータリスト\n",
    "tmp_columns = [\"test_spulit_num\",\"test_size\",\"train_score\",\"test_score\",\"X_train.shape\",\"X_test.shape\",\"X_train.shape[0]\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC Linear, SVC rbf, RandmForest, LogisticRegression、による計算をする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm linear::: i,j,best C: 0.2   0   {'C': 1}\n",
      "svm rbf::: i,j,best C: 0.2   0   {'C': 5}\n",
      "randam forest::: i,j,best C: 0.2   0   {'max_depth': 10, 'n_estimators': 10}\n",
      "logistic regression::: i,j,best C: 0.2   0   {'C': 5}\n",
      "svm linear::: i,j,best C: 0.5   0   {'C': 1}\n",
      "svm rbf::: i,j,best C: 0.5   0   {'C': 10}\n",
      "randam forest::: i,j,best C: 0.5   0   {'max_depth': 10, 'n_estimators': 10}\n",
      "logistic regression::: i,j,best C: 0.5   0   {'C': 5}\n",
      "svm linear::: i,j,best C: 0.9   0   {'C': 1}\n",
      "svm rbf::: i,j,best C: 0.9   0   {'C': 10}\n",
      "randam forest::: i,j,best C: 0.9   0   {'max_depth': 7, 'n_estimators': 10}\n",
      "logistic regression::: i,j,best C: 0.9   0   {'C': 5}\n",
      "svm linear::: i,j,best C: 0.93   0   {'C': 1}\n",
      "svm rbf::: i,j,best C: 0.93   0   {'C': 10}\n",
      "randam forest::: i,j,best C: 0.93   0   {'max_depth': 10, 'n_estimators': 10}\n",
      "logistic regression::: i,j,best C: 0.93   0   {'C': 10}\n",
      "svm linear::: i,j,best C: 0.96   0   {'C': 1}\n",
      "svm rbf::: i,j,best C: 0.96   0   {'C': 10}\n",
      "randam forest::: i,j,best C: 0.96   0   {'max_depth': 7, 'n_estimators': 10}\n",
      "logistic regression::: i,j,best C: 0.96   0   {'C': 1}\n",
      "svm linear::: i,j,best C: 0.98   0   {'C': 1}\n",
      "svm rbf::: i,j,best C: 0.98   0   {'C': 10}\n",
      "randam forest::: i,j,best C: 0.98   0   {'max_depth': 7, 'n_estimators': 10}\n",
      "logistic regression::: i,j,best C: 0.98   0   {'C': 5}\n",
      "svm linear::: i,j,best C: 0.99   0   {'C': 1}\n",
      "svm rbf::: i,j,best C: 0.99   0   {'C': 10}\n",
      "randam forest::: i,j,best C: 0.99   0   {'max_depth': 7, 'n_estimators': 10}\n",
      "logistic regression::: i,j,best C: 0.99   0   {'C': 5}\n",
      "svm linear::: i,j,best C: 0.999   0   {'C': 1}\n",
      "svm rbf::: i,j,best C: 0.999   0   {'C': 1}\n",
      "randam forest::: i,j,best C: 0.999   0   {'max_depth': 7, 'n_estimators': 10}\n",
      "logistic regression::: i,j,best C: 0.999   0   {'C': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    " \n",
    "\n",
    "# 解析用パラメータ保存データフレーム\n",
    "svm_liner_scores_for_each_size  = pd.DataFrame(index=[],columns=tmp_columns)\n",
    "svm_rbf_scores_for_each_size    = pd.DataFrame(index=[],columns=tmp_columns)\n",
    "randam_fo_scores_for_each_size  = pd.DataFrame(index=[],columns=tmp_columns)\n",
    "logistic_r_scores_for_each_size = pd.DataFrame(index=[],columns=tmp_columns)\n",
    "\n",
    "for i in test_size_list:\n",
    "    for j in range(test_split_num):\n",
    "        ### Traindata,TestData\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=i)\n",
    "        \n",
    "        ###\n",
    "        ### svm linear start\n",
    "        ###\n",
    "        parameters = {'C':[1, 5, 10]}\n",
    "        model = SVC(kernel=\"linear\")\n",
    "        clf = GridSearchCV(model, parameters, cv=3)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        print(\"svm linear::: i,j,best C:\", i ,\" \" , j ,\" \",clf.best_params_)\n",
    "        train_score = clf.best_estimator_.score(X_train, y_train)\n",
    "        test_score  = clf.best_estimator_.score(X_test , y_test)\n",
    "\n",
    "        tmp_df = pd.Series([j ,i ,train_score,test_score,X_train.shape,X_test.shape, X_train.shape[0]] ,index=tmp_columns)\n",
    "        svm_liner_scores_for_each_size = svm_liner_scores_for_each_size.append(\n",
    "            tmp_df, ignore_index=True)\n",
    "        \n",
    "        \n",
    "        ####\n",
    "        #### svm rbf start\n",
    "        ####\n",
    "        \n",
    "        parameters = {'C':[1, 5, 10]}\n",
    "        model = SVC(kernel=\"rbf\")\n",
    "        clf = GridSearchCV(model, parameters, cv=3)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        print(\"svm rbf::: i,j,best C:\", i ,\" \" , j ,\" \",clf.best_params_)\n",
    "        train_score = clf.best_estimator_.score(X_train, y_train)\n",
    "        test_score  = clf.best_estimator_.score(X_test , y_test)\n",
    "\n",
    "        tmp_df = pd.Series([j ,i ,train_score,test_score,X_train.shape,X_test.shape, X_train.shape[0]] ,index=tmp_columns)\n",
    "       \n",
    "        svm_rbf_scores_for_each_size = svm_rbf_scores_for_each_size.append(\n",
    "            tmp_df, ignore_index=True)\n",
    "\n",
    "        \n",
    "        ####\n",
    "        #### randam forest start\n",
    "        ####        \n",
    "        parameters = {'max_depth':[7,10,12], 'n_estimators':[10]}\n",
    "        model = RandomForestClassifier(min_samples_leaf=2, min_samples_split=2, random_state=1234)\n",
    "        clf = GridSearchCV(model, parameters ,cv=3)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        print(\"randam forest::: i,j,best C:\", i ,\" \" , j ,\" \",clf.best_params_)\n",
    "        train_score = clf.best_estimator_.score(X_train, y_train)\n",
    "        test_score  = clf.best_estimator_.score(X_test , y_test)\n",
    "\n",
    "        tmp_df = pd.Series([j ,i ,train_score,test_score,X_train.shape,X_test.shape, X_train.shape[0]] ,index=tmp_columns)       \n",
    "        randam_fo_scores_for_each_size = randam_fo_scores_for_each_size.append(\n",
    "            tmp_df, ignore_index=True)\n",
    "        \n",
    "        \n",
    "        ####\n",
    "        #### Logistic Regression\n",
    "        ####        \n",
    "        parameters = {'C':[1,5,10]}\n",
    "        model = LogisticRegression()\n",
    "        clf = GridSearchCV(model, parameters ,cv=3)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        print(\"logistic regression::: i,j,best C:\", i ,\" \" , j ,\" \",clf.best_params_)\n",
    "        train_score = clf.best_estimator_.score(X_train, y_train)\n",
    "        test_score  = clf.best_estimator_.score(X_test , y_test)\n",
    "\n",
    "        tmp_df = pd.Series([j ,i ,train_score,test_score,X_train.shape,X_test.shape, X_train.shape[0]] ,index=tmp_columns)       \n",
    "        logistic_r_scores_for_each_size = logistic_r_scores_for_each_size.append(\n",
    "            tmp_df, ignore_index=True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 1.05)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax =svm_liner_scores_for_each_size.plot(x=\"X_train.shape[0]\",y=\"test_score\")\n",
    "svm_rbf_scores_for_each_size.plot(x=\"X_train.shape[0]\",y=\"test_score\",ax=ax)\n",
    "randam_fo_scores_for_each_size.plot(x=\"X_train.shape[0]\",y=\"test_score\",ax=ax)\n",
    "logistic_r_scores_for_each_size.plot(x=\"X_train.shape[0]\",y=\"test_score\",ax=ax)\n",
    "ax.legend([\"svm linear\", \"svm rbf\", \"randam forest\",\"logistic reg.\"])\n",
    "plt.xlabel(\"number of training data samples.\")\n",
    "plt.ylabel(\"score using test data.\")\n",
    "plt.ylim(.5,1.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_spulit_num</th>\n",
       "      <th>test_size</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>X_train.shape</th>\n",
       "      <th>X_test.shape</th>\n",
       "      <th>X_train.shape[0]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(6499, 117)</td>\n",
       "      <td>(1625, 117)</td>\n",
       "      <td>6499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(4062, 117)</td>\n",
       "      <td>(4062, 117)</td>\n",
       "      <td>4062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997812</td>\n",
       "      <td>(812, 117)</td>\n",
       "      <td>(7312, 117)</td>\n",
       "      <td>812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.930</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996824</td>\n",
       "      <td>(568, 117)</td>\n",
       "      <td>(7556, 117)</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.960</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990641</td>\n",
       "      <td>(324, 117)</td>\n",
       "      <td>(7800, 117)</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.980</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.983672</td>\n",
       "      <td>(162, 117)</td>\n",
       "      <td>(7962, 117)</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.990</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.969912</td>\n",
       "      <td>(81, 117)</td>\n",
       "      <td>(8043, 117)</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.640710</td>\n",
       "      <td>(8, 117)</td>\n",
       "      <td>(8116, 117)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  test_spulit_num  test_size  train_score  test_score X_train.shape  \\\n",
       "0               0      0.200          1.0    1.000000   (6499, 117)   \n",
       "1               0      0.500          1.0    1.000000   (4062, 117)   \n",
       "2               0      0.900          1.0    0.997812    (812, 117)   \n",
       "3               0      0.930          1.0    0.996824    (568, 117)   \n",
       "4               0      0.960          1.0    0.990641    (324, 117)   \n",
       "5               0      0.980          1.0    0.983672    (162, 117)   \n",
       "6               0      0.990          1.0    0.969912     (81, 117)   \n",
       "7               0      0.999          1.0    0.640710      (8, 117)   \n",
       "\n",
       "  X_test.shape X_train.shape[0]  \n",
       "0  (1625, 117)             6499  \n",
       "1  (4062, 117)             4062  \n",
       "2  (7312, 117)              812  \n",
       "3  (7556, 117)              568  \n",
       "4  (7800, 117)              324  \n",
       "5  (7962, 117)              162  \n",
       "6  (8043, 117)               81  \n",
       "7  (8116, 117)                8  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_liner_scores_for_each_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_spulit_num</th>\n",
       "      <th>test_size</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>X_train.shape</th>\n",
       "      <th>X_test.shape</th>\n",
       "      <th>X_train.shape[0]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(6499, 117)</td>\n",
       "      <td>(1625, 117)</td>\n",
       "      <td>6499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(4062, 117)</td>\n",
       "      <td>(4062, 117)</td>\n",
       "      <td>4062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998906</td>\n",
       "      <td>(812, 117)</td>\n",
       "      <td>(7312, 117)</td>\n",
       "      <td>812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998941</td>\n",
       "      <td>(568, 117)</td>\n",
       "      <td>(7556, 117)</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.996914</td>\n",
       "      <td>0.984744</td>\n",
       "      <td>(324, 117)</td>\n",
       "      <td>(7800, 117)</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.980</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985431</td>\n",
       "      <td>(162, 117)</td>\n",
       "      <td>(7962, 117)</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966057</td>\n",
       "      <td>(81, 117)</td>\n",
       "      <td>(8043, 117)</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.481764</td>\n",
       "      <td>(8, 117)</td>\n",
       "      <td>(8116, 117)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  test_spulit_num  test_size  train_score  test_score X_train.shape  \\\n",
       "0               0      0.200     1.000000    1.000000   (6499, 117)   \n",
       "1               0      0.500     1.000000    1.000000   (4062, 117)   \n",
       "2               0      0.900     1.000000    0.998906    (812, 117)   \n",
       "3               0      0.930     1.000000    0.998941    (568, 117)   \n",
       "4               0      0.960     0.996914    0.984744    (324, 117)   \n",
       "5               0      0.980     1.000000    0.985431    (162, 117)   \n",
       "6               0      0.990     1.000000    0.966057     (81, 117)   \n",
       "7               0      0.999     0.750000    0.481764      (8, 117)   \n",
       "\n",
       "  X_test.shape X_train.shape[0]  \n",
       "0  (1625, 117)             6499  \n",
       "1  (4062, 117)             4062  \n",
       "2  (7312, 117)              812  \n",
       "3  (7556, 117)              568  \n",
       "4  (7800, 117)              324  \n",
       "5  (7962, 117)              162  \n",
       "6  (8043, 117)               81  \n",
       "7  (8116, 117)                8  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_rbf_scores_for_each_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_spulit_num</th>\n",
       "      <th>test_size</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>X_train.shape</th>\n",
       "      <th>X_test.shape</th>\n",
       "      <th>X_train.shape[0]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(6499, 117)</td>\n",
       "      <td>(1625, 117)</td>\n",
       "      <td>6499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(4062, 117)</td>\n",
       "      <td>(4062, 117)</td>\n",
       "      <td>4062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.998768</td>\n",
       "      <td>0.997949</td>\n",
       "      <td>(812, 117)</td>\n",
       "      <td>(7312, 117)</td>\n",
       "      <td>812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.998239</td>\n",
       "      <td>0.992456</td>\n",
       "      <td>(568, 117)</td>\n",
       "      <td>(7556, 117)</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.996914</td>\n",
       "      <td>0.982436</td>\n",
       "      <td>(324, 117)</td>\n",
       "      <td>(7800, 117)</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.980</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976639</td>\n",
       "      <td>(162, 117)</td>\n",
       "      <td>(7962, 117)</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979858</td>\n",
       "      <td>(81, 117)</td>\n",
       "      <td>(8043, 117)</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.481764</td>\n",
       "      <td>(8, 117)</td>\n",
       "      <td>(8116, 117)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  test_spulit_num  test_size  train_score  test_score X_train.shape  \\\n",
       "0               0      0.200     1.000000    1.000000   (6499, 117)   \n",
       "1               0      0.500     1.000000    1.000000   (4062, 117)   \n",
       "2               0      0.900     0.998768    0.997949    (812, 117)   \n",
       "3               0      0.930     0.998239    0.992456    (568, 117)   \n",
       "4               0      0.960     0.996914    0.982436    (324, 117)   \n",
       "5               0      0.980     1.000000    0.976639    (162, 117)   \n",
       "6               0      0.990     1.000000    0.979858     (81, 117)   \n",
       "7               0      0.999     0.750000    0.481764      (8, 117)   \n",
       "\n",
       "  X_test.shape X_train.shape[0]  \n",
       "0  (1625, 117)             6499  \n",
       "1  (4062, 117)             4062  \n",
       "2  (7312, 117)              812  \n",
       "3  (7556, 117)              568  \n",
       "4  (7800, 117)              324  \n",
       "5  (7962, 117)              162  \n",
       "6  (8043, 117)               81  \n",
       "7  (8116, 117)                8  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randam_fo_scores_for_each_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_spulit_num</th>\n",
       "      <th>test_size</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>X_train.shape</th>\n",
       "      <th>X_test.shape</th>\n",
       "      <th>X_train.shape[0]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(6499, 117)</td>\n",
       "      <td>(1625, 117)</td>\n",
       "      <td>6499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(4062, 117)</td>\n",
       "      <td>(4062, 117)</td>\n",
       "      <td>4062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998359</td>\n",
       "      <td>(812, 117)</td>\n",
       "      <td>(7312, 117)</td>\n",
       "      <td>812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995633</td>\n",
       "      <td>(568, 117)</td>\n",
       "      <td>(7556, 117)</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.996914</td>\n",
       "      <td>0.978974</td>\n",
       "      <td>(324, 117)</td>\n",
       "      <td>(7800, 117)</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.980</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982919</td>\n",
       "      <td>(162, 117)</td>\n",
       "      <td>(7962, 117)</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960338</td>\n",
       "      <td>(81, 117)</td>\n",
       "      <td>(8043, 117)</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.610399</td>\n",
       "      <td>(8, 117)</td>\n",
       "      <td>(8116, 117)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  test_spulit_num  test_size  train_score  test_score X_train.shape  \\\n",
       "0               0      0.200     1.000000    1.000000   (6499, 117)   \n",
       "1               0      0.500     1.000000    1.000000   (4062, 117)   \n",
       "2               0      0.900     1.000000    0.998359    (812, 117)   \n",
       "3               0      0.930     1.000000    0.995633    (568, 117)   \n",
       "4               0      0.960     0.996914    0.978974    (324, 117)   \n",
       "5               0      0.980     1.000000    0.982919    (162, 117)   \n",
       "6               0      0.990     1.000000    0.960338     (81, 117)   \n",
       "7               0      0.999     1.000000    0.610399      (8, 117)   \n",
       "\n",
       "  X_test.shape X_train.shape[0]  \n",
       "0  (1625, 117)             6499  \n",
       "1  (4062, 117)             4062  \n",
       "2  (7312, 117)              812  \n",
       "3  (7556, 117)              568  \n",
       "4  (7800, 117)              324  \n",
       "5  (7962, 117)              162  \n",
       "6  (8043, 117)               81  \n",
       "7  (8116, 117)                8  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_r_scores_for_each_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 説明変数を選ぶ。RandomForestでfittingし、importanceを利用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'max_depth':[5,7,10,12], 'n_estimators':[10,50,100,300]}\n",
    "cv = GridSearchCV(RandomForestClassifier(min_samples_leaf=2, min_samples_split=2, random_state=1234),param_grid=param_grid,cv=5)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "cv.fit(X_train, y_train)\n",
    "cv.best_estimator_.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            importance\n",
      "odor_n                        0.186815\n",
      "spore-print-color_h           0.096109\n",
      "gill-size_n                   0.066876\n",
      "bruises_t                     0.058053\n",
      "gill-color_b                  0.053312\n",
      "spore-print-color_n           0.047249\n",
      "stalk-root_e                  0.039223\n",
      "ring-type_p                   0.032305\n",
      "odor_f                        0.025732\n",
      "stalk-surface-below-ring_s    0.024403\n"
     ]
    }
   ],
   "source": [
    "importances = pd.DataFrame( cv.best_estimator_.feature_importances_, index=X.columns, columns=[\"importance\"])\n",
    "print(importances.sort_values(by=\"importance\", ascending=False).head(10))\n",
    "\n",
    "# importanceが高いほう、低いほうを、nn個ずつ抽出する。\n",
    "nn = 8 ## この値を変えて試す。\n",
    "importance_top = importances.sort_values(by=\"importance\", ascending=False).head(nn).index.tolist()\n",
    "importance_btm = importances.sort_values(by=\"importance\", ascending=False).tail(nn).index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importanceが高い説明変数のみを使い、計算をする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8124, 8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data, test dataを作る。\n",
    "y_top = dfm_d.class_p.to_frame()\n",
    "X_top = dfm_d.drop([\"class_p\",\"class_e\"], axis=1)\n",
    "X_top = X_top.loc[:,importance_top]\n",
    "\n",
    "X_top.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm linear::: i,j,best C: 0.2   0   {'C': 1}\n",
      "svm rbf::: i,j,best C: 0.2   0   {'C': 1}\n",
      "randam forest::: i,j,best C: 0.2   0   {'max_depth': 7, 'n_estimators': 10}\n",
      "logistic regression::: i,j,best C: 0.2   0   {'C': 1}\n",
      "svm linear::: i,j,best C: 0.5   0   {'C': 5}\n",
      "svm rbf::: i,j,best C: 0.5   0   {'C': 1}\n",
      "randam forest::: i,j,best C: 0.5   0   {'max_depth': 7, 'n_estimators': 10}\n",
      "logistic regression::: i,j,best C: 0.5   0   {'C': 1}\n",
      "svm linear::: i,j,best C: 0.9   0   {'C': 1}\n",
      "svm rbf::: i,j,best C: 0.9   0   {'C': 5}\n",
      "randam forest::: i,j,best C: 0.9   0   {'max_depth': 7, 'n_estimators': 10}\n",
      "logistic regression::: i,j,best C: 0.9   0   {'C': 1}\n",
      "svm linear::: i,j,best C: 0.93   0   {'C': 5}\n",
      "svm rbf::: i,j,best C: 0.93   0   {'C': 10}\n",
      "randam forest::: i,j,best C: 0.93   0   {'max_depth': 7, 'n_estimators': 10}\n",
      "logistic regression::: i,j,best C: 0.93   0   {'C': 5}\n",
      "svm linear::: i,j,best C: 0.96   0   {'C': 5}\n",
      "svm rbf::: i,j,best C: 0.96   0   {'C': 5}\n",
      "randam forest::: i,j,best C: 0.96   0   {'max_depth': 7, 'n_estimators': 10}\n",
      "logistic regression::: i,j,best C: 0.96   0   {'C': 5}\n",
      "svm linear::: i,j,best C: 0.98   0   {'C': 5}\n",
      "svm rbf::: i,j,best C: 0.98   0   {'C': 1}\n",
      "randam forest::: i,j,best C: 0.98   0   {'max_depth': 7, 'n_estimators': 10}\n",
      "logistic regression::: i,j,best C: 0.98   0   {'C': 1}\n",
      "svm linear::: i,j,best C: 0.99   0   {'C': 5}\n",
      "svm rbf::: i,j,best C: 0.99   0   {'C': 5}\n",
      "randam forest::: i,j,best C: 0.99   0   {'max_depth': 7, 'n_estimators': 10}\n",
      "logistic regression::: i,j,best C: 0.99   0   {'C': 5}\n",
      "svm linear::: i,j,best C: 0.999   0   {'C': 1}\n",
      "svm rbf::: i,j,best C: 0.999   0   {'C': 1}\n",
      "randam forest::: i,j,best C: 0.999   0   {'max_depth': 7, 'n_estimators': 10}\n",
      "logistic regression::: i,j,best C: 0.999   0   {'C': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 解析用パラメータ保存データフレーム\n",
    "svm_liner_scores_for_each_size_top  = pd.DataFrame(index=[],columns=tmp_columns)\n",
    "svm_rbf_scores_for_each_size_top    = pd.DataFrame(index=[],columns=tmp_columns)\n",
    "randam_fo_scores_for_each_size_top  = pd.DataFrame(index=[],columns=tmp_columns)\n",
    "logistic_r_scores_for_each_size_top = pd.DataFrame(index=[],columns=tmp_columns)\n",
    "\n",
    "for i in test_size_list:\n",
    "    for j in range(test_split_num):\n",
    "        ### Traindata,TestData\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_top, y_top, test_size=i)\n",
    "        \n",
    "        ###\n",
    "        ### svm linear start\n",
    "        ###\n",
    "        parameters = {'C':[1, 5, 10]}\n",
    "        model = SVC(kernel=\"linear\")\n",
    "        clf = GridSearchCV(model, parameters, cv=3)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        print(\"svm linear::: i,j,best C:\", i ,\" \" , j ,\" \",clf.best_params_)\n",
    "        train_score = clf.best_estimator_.score(X_train, y_train)\n",
    "        test_score  = clf.best_estimator_.score(X_test , y_test)\n",
    "\n",
    "        tmp_df = pd.Series([j ,i ,train_score,test_score,X_train.shape,X_test.shape, X_train.shape[0]] ,index=tmp_columns)\n",
    "        svm_liner_scores_for_each_size_top = svm_liner_scores_for_each_size_top.append(\n",
    "            tmp_df, ignore_index=True)\n",
    "       \n",
    "        \n",
    "        ####\n",
    "        #### svm rbf start\n",
    "        ####\n",
    "        \n",
    "        parameters = {'C':[1, 5, 10]}\n",
    "        model = SVC(kernel=\"rbf\")\n",
    "        clf = GridSearchCV(model, parameters, cv=3)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        print(\"svm rbf::: i,j,best C:\", i ,\" \" , j ,\" \",clf.best_params_)\n",
    "        train_score = clf.best_estimator_.score(X_train, y_train)\n",
    "        test_score  = clf.best_estimator_.score(X_test , y_test)\n",
    "\n",
    "        tmp_df = pd.Series([j ,i ,train_score,test_score,X_train.shape,X_test.shape, X_train.shape[0]] ,index=tmp_columns)\n",
    "       \n",
    "        svm_rbf_scores_for_each_size_top = svm_rbf_scores_for_each_size_top.append(\n",
    "            tmp_df, ignore_index=True)\n",
    "\n",
    "        \n",
    "        ####\n",
    "        #### randam forest start\n",
    "        ####        \n",
    "        parameters = {'max_depth':[7,10,12], 'n_estimators':[10]}\n",
    "        model = RandomForestClassifier(min_samples_leaf=2, min_samples_split=2, random_state=1234)\n",
    "        clf = GridSearchCV(model, parameters ,cv=3)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        print(\"randam forest::: i,j,best C:\", i ,\" \" , j ,\" \",clf.best_params_)\n",
    "        train_score = clf.best_estimator_.score(X_train, y_train)\n",
    "        test_score  = clf.best_estimator_.score(X_test , y_test)\n",
    "\n",
    "        tmp_df = pd.Series([j ,i ,train_score,test_score,X_train.shape,X_test.shape, X_train.shape[0]] ,index=tmp_columns)       \n",
    "        randam_fo_scores_for_each_size_top = randam_fo_scores_for_each_size_top.append(\n",
    "            tmp_df, ignore_index=True)\n",
    "        \n",
    "        \n",
    "        ####\n",
    "        #### Logistic Regression\n",
    "        ####        \n",
    "        parameters = {'C':[1,5,10]}\n",
    "        model = LogisticRegression()\n",
    "        clf = GridSearchCV(model, parameters ,cv=3)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        print(\"logistic regression::: i,j,best C:\", i ,\" \" , j ,\" \",clf.best_params_)\n",
    "        train_score = clf.best_estimator_.score(X_train, y_train)\n",
    "        test_score  = clf.best_estimator_.score(X_test , y_test)\n",
    "\n",
    "        tmp_df = pd.Series([j ,i ,train_score,test_score,X_train.shape,X_test.shape, X_train.shape[0]] ,index=tmp_columns)       \n",
    "        logistic_r_scores_for_each_size_top = logistic_r_scores_for_each_size_top.append(\n",
    "            tmp_df, ignore_index=True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importanceが高い説明変数を使った結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 1.05)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XmcFPWZ+PHP0z03l1yeoDBZkHOAYUCNLOKiiAoYFQ+UDYSNom40l66SXxSju1ETd92YeCFRjCd4bMSAihIRNRgZELkR5JDDwAAiMMzVXc/vj6pueprumWacmp5hnvfr1a+u+ta3qp4+n/rW8S1RVYwxxhiAQLoDMMYY03hYUjDGGBNlScEYY0yUJQVjjDFRlhSMMcZEWVIwxhgTZUnBGGNMlCUFY4wxUZYUjDHGRGWkO4Cj1aFDB+3SpUu6wzDGmCZlyZIlu1W1Y231mlxS6NKlC8XFxekOwxhjmhQR2ZJKPdt9ZIwxJsqSgjHGmChLCsYYY6IsKRhjjImypGCMMSbKkoIxxpgoSwrGGGOiLCkYY4yJsqRgjDEmypKCMcaYKEsKxhhjoiwpGGOMibKkYIwxJsqSgjHGmCjfkoKIPCUiu0RkZZLpIiIPi8gGEVkuIoV+xWKMMSY1frYUZgAja5h+IdDNe1wPPOZjLMYYY1LgW1JQ1YXA3hqqXAL8SV0fA8eJyEl+xWOMMaZ26TymcAqwNWZ8m1dmjDEmTdKZFCRBmSasKHK9iBSLSHFJSYnPYRljTPOVzqSwDegcM94J2JGooqpOU9UiVS3q2LHW+04bY4ypo3QmhdnA972zkM4EvlHVr9IYjzHGNHsZfi1YRF4EhgEdRGQbMBXIBFDVx4G5wEXABuAQ8AO/YjGmOVFVwhrGUYewhlFVRISgBAlIgKAEEUm099YYH5OCqo6rZboC/+7X+k3jp46DqqKqOE7YG3ZwwmHCGibshKgKhwiFQ4Q1RDgcwnFChJwwoXAVIcet54RDhDVMSN26jjdv2Am7Dw0RdhwcDRFyQoTVwYk8a9hdjhPGUfcRVic6HvlzdZcZJoyDE3n2/nTd6U50XkcdHA4/R+ug0bphYutpTH2NloVx0Mg8aLVp7pya4OEkPjAXRwBBCCAECBBAEIkZlwABOTws3nNQItOCBCWARMuCBAPBaHkgECTolQUDGW5CCgTJiIwHMsgIZnjLCkSTVexzyuWBIIKX9AKBI5Jf/PzJyqstN2Y5AQJHLLe2+GKHm1oC9i0pNCW7D1bws1mfUVoRcv+YAFXvqLcqF5b9hRGV88nLCpKbnUFeViaZQfdnhfeBH0T5NFBFsVSyiioyRGhJkJYEaCEBWhKkhQRpSZA8CRKsEqiCcIWiVQ5h3PU64v0xivvjV9Qrc58jP35FceDwH4Hg/llE6xCdN1LPXb5bHkZxJKYcCMvhOpFlhL36TrTcLXO8eRyBcMy0xGVCuFqZRJcRjh0WiT43dqJKEAiqEgCCQECVDCCgEEC9MshACSgEo8/ucFAhyyvLwJ0nMv3wsrzleOuKLDOIu96MyPq9dbpl3vpjymI/Bwep/jl55Yr7eRz+/IQwXnnks0lWHvlcARV3OVUx5YfXJ9XWGymLXa7jLbP6d6nxfyeSiSZfCcQ8H04YQWKTiZtgA9HEGogm1KAEmdRnEiO/c6Gv8VpSAN5c+Q8Wfl7CmfntyAgEI//ziAhnl77L5NLH2BD8DmsP5KH7FSFMOBu2t3L4IjfMqsxK1ksljrhvaHeyCKiynUpKcTioSpno4XOrlMg/A+Sk5SUD4v15eV9YFQLgPSJlMcO40yVm3N0+w5vX+7IrZEqAbAWJ/AjitkijW6DxPxYC3tZqgGBka9WrIxIkGK3j/XiidQLVf1QEkOjWmztefesuWG2LNyABMiRIQDK8ZXtbuNHp7hZtRsAdDkoACbjrQNwtbAkE3HdDBLxht07gcB0JgPdH4E4Td57IsAiIu1UKkXoSXUYgEEw4T6ScaFyRcm/9gOOECYVCaNhtcWnYbU054dhHGMcJ44TDaMw0jSlzh91nDYdAwzhhB9UQeOU4YXe6EwY9XI+YMhwHcSL1HUTD0TqRYXHCoO400bC7Dg27G00aBtxhNERkM0Y1zOHNIsddJoojDqiDioOoAxKzaSUas2l0uIz4jRWqJ6z4hFgt8cWUJ0y43rATX55o+THlWw+9BZYU/Pf+uhI6t8vlxevOrN7U2/QBPPs/0OWfaTf2j6zbuYx3Ny1iWclSdlduBhR1MgiXdUbL8jkppzeDThxArxPbs3nPIVZs/4YNO/ZTVuV+gVvmOnQ/MYPvnJjBqR2CnNQW8nKqCGu4WpM18gjE/EHFN1ODgeCRzeLAkfPVVMcYk5w6Do7jEA6HCIeq3OdwuFpiDYWr4pKol1hDVe4u0Zgk6oTDaLjKHY4kzmhirZ5QDyfWULVk2rHPBb6/7mafFCpDDou+2M2lhadUTwgl62DmtdAun9+cfgbPvnoeADnBHPod34+rTriIohOKOCmnO2u/KmPZ1n0s27qPt1bsYdbineRmBulzSmvGDT6Vgk5t6NupDV3btyAQaLrNYFM3qurtj1RwHPCOoxzVuKNA8vEa66gimZmHH1lZ1cYJ2oHnRCQQIBgIEMzIgOy0NekbXLNPCku2fE1pZZhzuh9/uPDgLnh+LASzeOfcn/Bs8X2Mzh/NladfSe/2vckMZlZbxinHtWZ4zxMAcBxl5/5yOuQECISq0MpKtKoKLf+aqs273PFIWWQ4HPZ+xJEfOKBOTFmCccdr6kbm8f4Aqo2ruk3mbzke/YOJ/EmRaDwSZ4JlJJ2nhnHvoHP0tdbDeKK4lNjXmsIyHO9A7lGMN3oi1ZNGkuThlmVCKvUyM5HMrGrzVRuPW2bty7Lk1VCafVJ4//MSMgLCWd9p7xZUHoIXr4aDJfxj3J+4+5Nf0ad9H3519q/IDGQeMX943z7K166jfO0aKtaspXzNGio2bmRfKNTAr6QeBQIx+8ZTGPeG3efD+7xTHvf2hx9eDtH96DWNSyCYYn133zwkH0+4jEAgpk78eJJlVnst8a/t6Mfxjj+464kfj4lLJFpHIq8hMg9AKIQT2RipqgLvudqjMjJcGTNc/eGUlaP7DxzeqEm0nKoqCIfr/3sZm7xqSB6xySsQU++IZJZ0WcmSV9aRSSzRI6Np/6027ejrwfufl1DUpS0tszPACcNr18H2pYSv/BO/2PASVU4VDwx9gAzJoHLbdirWrqHc+/MvX7uG0I7D19tlHH882T170PKcoQRator7EmUd/jJlZR3+smZlQSDo/pijf1BxP/b4ce8HH/0TSjQePXCZ+ni0zJhvScNhNBQ6MnFUSzYx05IkmCOSV43LO1zHOVSGVu0nlCRpRer50pILBGpOGomSUUyiqakl1vLss8np1av+Y47RrJPCrv3lrPlqP1MHHsfWyTcQ3rIC3f8PaFXA7kUPctWhEm7JPZ6q527g8z17cPbvd2cMBMjq2pW8AYXkXNOD7J49yenRg4z27dP7goxpJCQYRIJByM5Odyg10nA4ScJIlqyStI7i6h2ZzBK3wpxDh2pdllZWursigWCr1pYU/LRw/W6yQxWc8fT9HPrqS3Jb74fjT+Vgu06sLVlGh7Yn0OGEfkgwSKBNG3J69CSnZw+yu3UjkJub7vCNMd9SNHnlNO4DyZHk5e469FezTQord69k/tpvuH3la8iWLzhl6B5aDvsXSi97ghvnjKPKOYWXR79Mm+w26Q7VGNPMRZNXA2iWSWFf+T7Gzx3PyI9acNbmvXQsrKRlv+/A5dO575P72HZwG09d8JQlBGNMs9Msr2BatWcVPTZXMX7hXtZ1E/L6VsHVz/HW9g94/YvXua7vdQw8YWC6wzTGmAbXLJPC6p3L+fHrDgdaB7lvlPDTnoPYkhHknkX3UNCxgBv63ZDuEI0xJi2aZVLYuraY40qhV4/d3HHKd/nbN58zdvZYHBzu/+f7yQg0y71qxhjTPJPC/vVrACg5pSeXXvQEUwZPocqp4pdn/pLOrTrXMrcxxhy7mt0m8a5Du2j51TcA7Ok+lH8KBLim5zV875++R15mXpqjM8aY9Gp2LYVVu1dx8h5Fcx0CrdpGyy0hGGNMc0wKe1Zxyh7IaVVFIKdFusMxxphGpdklhZW7V9DpayG3dYiM7JbpDscYYxqVZpUUVJWtW1aRV+aQ3TpE0FoKxhhTTbNKCjtKd9Diq30AZLUKkZXbKs0RGWNM49KsksLK3Ss5ea/b22B26xCZubb7yBhjYjWrpLBqzyo67RU0M4OMvDDZ1lIwxphqmldS2L2Kbt/k4bRvhQhk51lLwRhjYjWbpOCow+o9qzl5rxJu6x5gzm1hScEYY2I1m6SwZf8WKsoO0GJ3KU5b94YaObb7yBhjqmk2SWHVnlWc+DWIozitsyjTLAINdNMKY4xpKppNUqgIVVBwyL2HstNaKJfGffs9Y4xJh2aTFC7vfjm3Hj/OHWkJ5dK4byhujDHp0GySAkDFxo1knHQSQamgwloKxhhzhGaVFCo3bSa7a1cywmVUBnLTHY4xxjQ6viYFERkpIutEZIOI3JFg+mkiMl9ElovIAhHp5Fcsqkrlxo1k5eeTES6jKmAtBWOMiVenpCAio1KoEwQeAS4EegHjRKRXXLUHgT+pagFwD3BfXeJJRWhXCU5pKVldu5DllBEKWkvBGGPi1bWlMCiFOoOBDaq6UVUrgZeAS+Lq9ALme8PvJZhebyo3bQIgOz+fLC0nHLSWgjHGxKtTUlDVqSlUOwXYGjO+zSuL9RlwuTd8KdBKRNrXJabaVG7aCEBWfj7ZTjnhDLvTmjHGxEvpHs0i0gd3qz66ea2qf6pttgRlGjd+K/AHEZkILAS2A6EE678euB7g1FNPTSXkI2SefDKtR40i4/jjyaYCJ8N2HxljTLxak4KITAWG4SaFubjHCD4EaksK24DOMeOdgB2xFVR1B3CZt56WwOWq+k38glR1GjANoKioKD6xpKTlOefQ8pxzAMjVCjTTbrBjjDHxUtl9NBYYDvxDVX8A9ANSufJrMdBNRLqKSBZwNTA7toKIdBCRSAxTgKdSjryOwqEQ2VKFZtruI2OMiZdKUihTVQcIiUhrYBeQX9tMqhoCfgS8DawBZqnqKhG5R0TGeNWGAetE5HPgBOC/6vAajsqh0v0ASJYlBWOMiZfKMYViETkOeBJYAhwEPkll4ao6F3eXU2zZXTHDrwCvpBxtPagoPUArQLJs95ExxsSrNSmo6k3e4OMi8hbQWlWX+xuWf8oPHQAgkG1JwRhj4tW6+0hEItcRoKqbVXV5bFlTU1F2EICMbNt9ZIwx8ZK2FEQkB8gDOohIWw6fYtoaOLkBYvNFVZnbUgjm2F3XjDEmXk27jyYDP8FNAEs4nBT243Zf0SRVlbsthcxcSwrGGBMvaVJQ1d8BvxORm1X19w0Yk69C5aUAZFpLwRhjjpDKgebf1/GK5kYpXOEmhSxrKRhjzBH8vKK5UXK8pJCd1yrNkRhjTOPj5xXNjZJT6SaFnLzWaY7EGGMaH9+uaG6s1EsKuS2spWCMMfF8vaK5Uao8RJUGycq2+ykYY0y8ZndFs1QdolyyyEx3IMYY0wjVdPFaYU3TVHWpPyH5KxA6RDk52M4jY4w5Uk0thf/2nnOAIty7pAlQAPwdGOJvaP4IhsqoENt1ZIwxiSQ90Kyq56rqucAWoFBVi1R1IDAA2NBQAda3QLicioAlBWOMSSSVs496qOqKyIiqrgT6+xeSvzLDh6gK2K04jTEmkVTOPlojItOB53DvsTwe96Y5TVJmuJzKoPWQaowxiaSSFH4A3Aj82BtfCDzmW0Q+y3LKOZTVPt1hGGNMo5TKKanlwEPeo8nL0jLCGbb7yBhjEknlmMIxJVsrcCwpGGNMQs0uKeRqOU6GHVMwxphEUrkd5xWplDUF6jjkUgFZlhSMMSaRVFoKU1Isa/Qqyg8REEUzLSkYY0wiNXVzcSFwEXCKiDwcM6k1EPI7MD+UHzpIDiBZLdIdijHGNEo1nX20AygGxuD2jhpxAPipn0H5pfzQAQAClhSMMSahmu7R/BnwmYi8oKpVACLSFuisql83VID1qSKSFHIsKRhjTCKpHFN4R0Rai0g73E7xnhaR//E5Ll9Ulh0EICPb7s9sjDGJpJIU2qjqfuAy4GmvU7zz/A3LH9GkYC0FY4xJKJWkkCEiJwFXAn/xOR5fhcrdpJBpScEYYxJKJSncA7wNfKGqi0UkH1jvb1j+CJW792fOyrVb7BhjTCKp9H30MvByzPhG4HI/g/JLuMJtKVhSMMaYxFK5orm7iMwXkZXeeIGI/NL/0OqfVh4CIDvPDjQbY0wiqew+ehL3CuYqAFVdDlydysJFZKSIrBORDSJyR4Lpp4rIeyLyqYgsF5GLjib4o6WV7u6j3BbWUjDGmERSSQp5qvpJXFmtVzSLSBB4BLgQ6AWME5FecdV+CcxS1QG4iebRFOKps0hLITfPkoIxxiSSSlLYLSLfwb3rGiIyFvgqhfkGAxtUdaOqVgIvAZfE1VHcbjMA2uBeRe0bqTpEmWYRCAb9XI0xxjRZqdx57d+BaUAPEdkObAKuTWG+U4CtMePbgDPi6twNzBORm4EWJLn+QUSuB64HOPXUU1NYdWJSVUq55GB3UzDGmMRSaSmoqp4HdAR6qOqQFOeTRMuKGx8HzFDVTrid7z0rIkcsW1WnqWqRqhZ17NgxhVUnFgiVUUF2nec3xphjXSp/7q8CqGqpqh7wyl5JYb5tQOeY8U4cuXvo34BZ3vIXATlAhxSWXSfBUBkVgRy/Fm+MMU1eTV1n9wB6A21E5LKYSa1x/7xrsxjoJiJdge24B5KviavzJTAcmCEiPb3llqQe/tHJCJdRaUnBGGOSqumYwunAKOA4YHRM+QHgutoWrKohEfkR7tXQQeApVV0lIvcAxao6G/g58KSI/BR319JEVY3fxVRvLCkYY0zNauo6+3XgdRE5y9u1c9RUdS4wN67srpjh1cDZdVl2XWQ65RzKatdQqzPGmCan1mMKdU0IjVGWlhMO2rlHxhiTTCoHmo8Z2U454Qy7P7MxxiTTrJJCDuU4GdZSMMaYZGq9eE1Efpag+Btgiaouq/+Q/JOrFTiZ1lIwxphkUmkpFAE34F6hfArulcXDcM8a+g//Qqtf4VCIbKkCSwrGGJNUKkmhPVCoqj9X1Z/jJomOwFBgoo+x1atDpfsBkCxLCsYYk0wqSeFUoDJmvAo4TVXLgApfovJBRal7MbZk2a04jTEmmVQ6xHsB+FhEXvfGRwMvikgLYLVvkdWz8kNuUghYUjDGmKRSuR3nvSLyJu5FZgLcoKrF3uRUekttFCq9+zMHcywpGGNMMqm0FAA+xe3MLgPcO6ap6pe+ReWDyjK3pZCRbbfiNMaYZFI5JfVmYCqwEwjjthYUKPA3tPpVVea2FDJyLSkYY0wyqbQUfgycrqp7/A7GT6Fyt6WQZUnBGGOSSuXso624F6s1aeEKt6WQmWNJwRhjkkmlpbARWCAic4g5BVVV/8e3qHzgeEkhO8+SgjHGJJNKUvjSe2R5jybJqXSTQm5eqzRHYowxjVcqp6T+qiEC8VsguxVbAp04sYUlBWOMSUaS3ehMRP5XVX8iIm/gnm1UjaqO8Tu4RIqKirS4uLj2isYYY6JEZImqFtVWr6aWwrPe84P1E5IxxpjGrqbbcS7xnt+PlIlIW6Czqi5vgNiMMcY0sFpPSRWRBSLSWkTaAZ8BT4tIkzrzyBhjTGpSuU6hjaruBy4DnlbVgcB5/oZljDEmHVJJChkichJwJfAXn+MxxhiTRqkkhXuAt4ENqrpYRPKB9f6GZYwxJh1SuU7hZeDlmPGNwOV+BmWMMSY9Uukl9WkSX6cwyZeIjDHGpE0q3VzEHkfIAS7FvbeCMcaYY0wqu49ejR0XkReBd32LyBhjTNqkcqA5Xjfg1PoOxBhjTPqlckzhANWPKfwDuN23iIwxxqRNKruPrFtRY4xpJuqy+yhlIjJSRNaJyAYRuSPB9IdEZJn3+FxE9vkZjzHGmJqlcvZRnYhIEHgEOB/YBiwWkdmqujpSR1V/GlP/ZmCAX/EYY4ypnZ8thcG4V0FvVNVK4CXgkhrqjwNe9DEeY4wxtUgpKYjIEBH5gTfcUUS6pjDbKcDWmPFtXlmi5Z8GdAX+mko8xhhj/JFK19lTcc82muIVZQLPpbBsSVCW+DZvcDXwiqqGk8RwvYgUi0hxSUlJCqs2xhhTF6m0FC4FxgClAKq6A0jljKRtQOeY8U4kvxL6amrYdaSq01S1SFWLOnbsmMKqjTHG1EUqSaFS3Rs5K4CItEhx2YuBbiLSVUSycP/4Z8dXEpHTgbbAohSXa4wxxiepJIVZIvIEcJyIXIfbxcWTtc2kqiHgR7jdbq8BZqnqKhG5R0TGxFQdB7zkJR5jjDFpJKn8F4vI+cAI3OMEb6vqO34HlkxRUZEWFxena/XGGNMkicgSVS2qrV6N1yl41xq8rarnAWlLBMYYYxpGjbuPvLOBDolImwaKxxhjTBqlckVzObBCRN7BOwMJQFVv8S0qY4wxaZFKUpjjPYwxxhzjUukl9RnvlNLuXtE6Va3yNyxjjDHpkMr9FIYBzwCbcc8+6iwiE1R1ob+hGWOMaWip7D76b2CEqq4DEJHuuFcfD/QzsKNRVVXFtm3bKC8vT3copgY5OTl06tSJzMzMdIdijEkilaSQGUkIAKr6uYg0ql/1tm3baNWqFV26dEEkUZdLJt1UlT179rBt2za6dk2lP0VjTDqkckVzsYj8UUSGeY8ngSV+B3Y0ysvLad++vSWERkxEaN++vbXmjGnkUmkp3Aj8O3AL7jGFhcCjfgZVF5YQGj/7jIxp/FJpKWQAv1PVy1T1UuBhIOhvWCbW5s2b6dOnDwDFxcXccotdImKM8UcqLYX5wHnAQW88F5gHfNevoExyRUVFFBXV2n3JtxIOhwkGLe8b0xyl0lLIUdVIQsAbzvMvpKantLSUiy++mH79+tGnTx9mzpzJm2++yZVXXhmts2DBAkaPHg1Ay5Ytuf322xk4cCDnnXcen3zyCcOGDSM/P5/Zs4/oXbyaBQsWMGrUKADuvvtuJk2aFJ334YcfjtZ77rnnGDx4MP3792fy5MmEw+79i2688UaKioro3bs3U6dOjdbv0qUL99xzD0OGDOHll1+ut/fGGNO0pNJSKBWRQlVdCiAiA4Eyf8Oqu1+9sYrVO/bX6zJ7ndyaqaN7J53+1ltvcfLJJzNnjnvh9zfffEOLFi2YPHkypaWltGjRgpkzZ3LVVVcBbhIZNmwYDzzwAJdeeim//OUveeedd1i9ejUTJkxgzJgxSdcVb+3atbz33nscOHCA008/nRtvvJENGzYwc+ZMPvroIzIzM7npppt4/vnn+f73v89//dd/0a5dO8LhMMOHD2f58uUUFBQA7imjH3744bd4p4wxTV0qLYWfAC+LyAci8gEwE/c+CcbTt29f3n33XW6//XY++OAD2rRpQ0ZGBiNHjuSNN94gFAoxZ84cLrnkEgCysrIYOXJkdN5zzjmHzMxM+vbty+bNm49q3RdffDHZ2dl06NCB448/np07dzJ//nyWLFnCoEGD6N+/P/Pnz2fjxo0AzJo1i8LCQgYMGMCqVatYvXp1dFmRpGWMab5S6eZisYj0AE7HPftobWPu5qKmLXq/dO/enSVLljB37lymTJnCiBEjuOuuu7jqqqt45JFHaNeuHYMGDaJVK/cuppmZmdEzcQKBANnZ2dHhUCh0VOuOzAsQDAYJhUKoKhMmTOC+++6rVnfTpk08+OCDLF68mLZt2zJx4sRqp4i2aJHqTfWMMceqWlsKInIF7nGFlcAlwEwRKfQ9siZkx44d5OXlMX78eG699VaWLl0KwLBhw1i6dClPPvlkg26FDx8+nFdeeYVdu3YBsHfvXrZs2cL+/ftp0aIFbdq0YefOnbz55psNFpMxpmlI5ZjCnar6sogMAS4AHgQeA87wNbImZMWKFdx2220EAgEyMzN57LHHAHfLfdSoUcyYMYNnnnmmweLp1asX//mf/8mIESNwHIfMzEweeeQRzjzzTAYMGEDv3r3Jz8/n7LPPbrCYjDFNQ6234xSRT1V1gIjcB6xQ1RciZQ0TYnWJbse5Zs0aevbsmY5wzFGyz8qY9Ej1dpypHGjeLiJPAFcCc0UkO8X5jDHGNDGp/LlfCbwNjFTVfUA74DZfozLGGJMWqZx9dAh4LWb8K+ArP4MyxhiTHrYbyBhjTJQlBWOMMVGWFIwxxkRZUmiCYrvSjvfBBx/Qu3dv+vfvT1lZo+2iyhjTSFlSaGIivZ0m8/zzz3PrrbeybNkycnNzGygqY8yxwpJCPfC76+wFCxZw7rnncs0119C3b18AQqEQEyZMoKCggLFjx3Lo0CGmT5/OrFmzuOeee7j22msb5sUbY44pqXRz0bS8eQf8Y0X9LvPEvnDh/UknN0TX2Z988gkrV66ka9eubN68mXXr1vHHP/6Rs88+m0mTJvHoo49y66238uGHHzJq1CjGjh1bv++BMaZZsJZCPWiIrrMHDx5M165do+OdO3eO9l00fvx4uw+CMaZeHHsthRq26P3SEF1nx3drHZk/2bgxxtSFry0FERkpIutEZIOI3JGkzpUislpEVonIC37G45d0dJ395ZdfsmjRIgBefPFFhgwZUq/LN8Y0T761FEQkCDwCnA9sAxaLyGxVXR1TpxswBThbVb8WkeP9isdP6eg6u2fPnjzzzDNMnjyZbt26ceONN9br8o0xzVOtXWfXecEiZwF3q+oF3vgUAFW9L6bOb4DPVXV6qsu1rrObNvusjEmP+uw6u65OAbbGjG/zymJ1B7qLyEci8rGIjEy0IBG5XkSKRaS4pKTEp3CNMcb4mRQSHfmMb5ZkAN2AYcA4YLqIHHfETKrTVLVIVYs6duxY74EaY4xx+ZkUtgGdY8Y7ATsS1HldVatUdROwDjdJGGOMSQM/k8JioJuIdBWRLOBqIP5y3T8D5wKISAfc3UkbfYzJGGNMDXxLCqoaAn6Ee9e2NcAsVV0lIveISOSS3beBPSKyGngPuE1V9/gVkzFCu2QoAAAT1klEQVTGmJr5evGaqs4F5saV3RUzrMDPvIcxxpg0s24uGqkuXbqwe/fuel/ubbfdRu/evbntNn9us71v3z4effRRX5ZtjPHfsdfNRZqpKqpKINA48+0TTzxBSUlJtGuN2oRCITIyUv+aRJLCTTfdVNcQjTFp1Dj/uZqYzZs307NnT2666SYKCwvZunUrN954I0VFRfTu3ZupU6dG63bp0oWpU6dSWFhI3759Wbt2LQB79uxhxIgRDBgwgMmTJxN7UeH3vvc9Bg4cSO/evZk2bVq0/Gi74B4zZgylpaWcccYZzJw5ky1btjB8+HAKCgoYPnw4X375JQATJ07kZz/7Geeeey633347paWlTJo0iUGDBjFgwABef/11AFatWsXgwYPp378/BQUFrF+/njvuuIMvvviC/v37+9YaMcb4x7crmv1S2xXND3zyAGv3rq3XdfZo14PbB9+edPrmzZvJz8/nb3/7G2eeeSYAe/fupV27doTDYYYPH87DDz9MQUEBXbp04ec//zk333wzjz76KEuXLmX69OnccsstdOjQgbvuuos5c+YwatQoSkpK6NChQ3RZZWVlDBo0iPfff5/27dsjIsydO5cLL7yQSy+9lNLSUubMmRPtgnvZsmVHxNqyZUsOHjwIwOjRoxk7diwTJkzgqaeeYvbs2fz5z39m4sSJ7N69m9dff51gMMgvfvELevXqxfjx49m3bx+DBw/m008/5Y477uDMM8/k2muvpbKyknA4zM6dOxk1ahQrV65M+F7ZFc3GpEdjuKK5WTnttNOiCQFg1qxZFBYWMmDAAFatWsXq1dEun7jssssAGDhwYLSr7IULFzJ+/HgALr74Ytq2bRut//DDD9OvXz/OPPNMtm7dyvr164G6dcEda9GiRVxzzTUA/Ou//mu17revuOIKgsEgAPPmzeP++++nf//+DBs2jPLycr788kvOOussfv3rX/PAAw+wZcsWu9ObMceAY+6YQk1b9H6K7dp606ZNPPjggyxevJi2bdsyceJEysvLo9Mj+/ODwWC1rrITdX+9YMEC3n33XRYtWkReXl70Txnq1gV3TWLXH/t6VJVXX32V008/vVr9nj17csYZZzBnzhwuuOACpk+fTn5+/lGv1xjTeFhLwQf79++nRYsWtGnThp07d/Lmm2/WOs/QoUN5/vnnAXjzzTf5+uuvAfcubm3btiUvL4+1a9fy8ccf11uc3/3ud3nppZcA997OybrfvuCCC/j9738fPc7x6aefArBx40by8/O55ZZbGDNmDMuXL6dVq1YcOHCg3mI0xjQsSwo+6NevHwMGDKB3795MmjQpeoe0mkydOpWFCxdSWFjIvHnzOPXUUwEYOXIkoVCIgoIC7rzzzmq7qL6thx9+mKeffpqCggKeffZZfve73yWsd+edd1JVVUVBQQF9+vThzjvvBGDmzJn06dOH/v37s3btWr7//e/Tvn17zj77bPr06WMHmo1pgo65A82mcbPPypj0sAPNxhhjjpolBWOMMVGWFIwxxkRZUjDGGBNlScEYY0yUJQVjjDFRlhTqScuWLes87w9/+MNq3WDEmzFjBjt27Ei5vjHG1NUx181FUzR9+vQap8+YMYM+ffpw8sknp1Q/maPtBtsY0/xYS6GeqSq33XYbffr0oW/fvsycORMAx3G46aab6N27N6NGjeKiiy7ilVdeAWDYsGEUFxcTDoeZOHFidN6HHnqIV155heLiYq699lr69+9PWVlZtD7AW2+9RWFhIf369WP48OFHxDNjxgyuuOIKRo8ezYgRIwD47W9/y6BBgygoKKjWrfe9995Ljx49OP/88xk3bhwPPvig32+XMaaROeY2G//x619TsaZ+u87O7tmDE3/xi5TqvvbaayxbtozPPvuM3bt3M2jQIIYOHcpHH33E5s2bWbFiBbt27aJnz55MmjSp2rzLli1j+/bt0W6n9+3bx3HHHccf/vAHHnzwQYqKql+MWFJSwnXXXcfChQvp2rUre/fuTRjTokWLWL58Oe3atWPevHmsX7+eTz75BFVlzJgxLFy4kLy8PF599VU+/fRTQqEQhYWFDBw4sA7vljGmKTvmkkK6ffjhh4wbN45gMMgJJ5zAOeecw+LFi/nwww+54oorCAQCnHjiiZx77rlHzJufn8/GjRu5+eabufjii6Nb9sl8/PHHDB06lK5duwLQrl27hPXOP//86LR58+Yxb948BgwYAMDBgwdZv349Bw4c4JJLLol2fz169Og6vwfGmKbrmEsKqW7R+yVZX1Kp9DHVtm1bPvvsM95++20eeeQRZs2axVNPPVXjuhJ1tx0vvhvsKVOmMHny5Gp1HnrooVqXY4w59tkxhXo2dOhQZs6cSTgcpqSkhIULFzJ48GCGDBnCq6++iuM47Ny5kwULFhwx7+7du3Ech8svv5x7772XpUuXAiTtjvqss87i/fffZ9OmTQBJdx/FuuCCC3jqqaeid1/bvn07u3btYsiQIbzxxhuUl5dz8OBB5syZ8y3eBWNMU3XMtRTS7dJLL2XRokX069cPEeE3v/kNJ554Ipdffjnz58+nT58+dO/enTPOOIM2bdpUm3f79u384Ac/wHEcAO677z7AvWfyDTfcQG5uLosWLYrW79ixI9OmTeOyyy7DcRyOP/543nnnnRrjGzFiBGvWrOGss84C3FNpn3vuOQYNGsSYMWPo168fp512GkVFRdH4Hn/8cQBuuOGG+nmTjDGNlnWd3YAOHjxIy5Yt2bNnD4MHD+ajjz7ixBNPTHdYUZH4Dh06xNChQ5k2bRqFhYX1uo6m8lkZc6xJtetsayk0oFGjRrFv3z4qKyu58847G1VCALj++utZvXo15eXlTJgwod4TgjGm8bOk0IASHUdoTF544YV0h2CMSTM70GyMMSbqmEkKTe3YSHNkn5Exjd8xkRRycnLYs2eP/ek0YqrKnj17yMnJSXcoxpgaHBPHFDp16sS2bdsoKSlJdyimBjk5OXTq1CndYRhjauBrUhCRkcDvgCAwXVXvj5s+EfgtsN0r+oOqHnUXoJmZmdGuHowxxtSdb0lBRILAI8D5wDZgsYjMVtX4GwHMVNUf+RWHMcaY1Pl5TGEwsEFVN6pqJfAScImP6zPGGPMt+ZkUTgG2xoxv88riXS4iy0XkFRHp7GM8xhhjauHnMYVE3XfGnx70BvCiqlaIyA3AM8C/HLEgkeuB673RgyKyro4xdQB213HedLPY06Opxt5U4waL3S+npVLJt76PROQs4G5VvcAbnwKgqvclqR8E9qpqm0TT6ymm4lT6/miMLPb0aKqxN9W4wWJPNz93Hy0GuolIVxHJAq4GZsdWEJGTYkbHAGt8jMcYY0wtfNt9pKohEfkR8DbuKalPqeoqEbkHKFbV2cAtIjIGCAF7gYl+xWOMMaZ2vl6noKpzgblxZXfFDE8BpvgZQ5xpDbiu+maxp0dTjb2pxg0We1o1ufspGGOM8c8x0feRMcaY+tEskoKIjBSRdSKyQUTuSHc8ACLylIjsEpGVMWXtROQdEVnvPbf1ykVEHvbiXy4ihTHzTPDqrxeRCQ0Ue2cReU9E1ojIKhH5cVOJX0RyROQTEfnMi/1XXnlXEfm7F8dM7+QIRCTbG9/gTe8Ss6wpXvk6EbnA79i9dQZF5FMR+UtTittb72YRWSEiy0Sk2CtrCt+Z47zrqNZ63/mzmkLcdaaqx/QD9yD3F0A+kAV8BvRqBHENBQqBlTFlvwHu8IbvAB7whi8C3sS99uNM4O9eeTtgo/fc1htu2wCxnwQUesOtgM+BXk0hfi+Glt5wJvB3L6ZZwNVe+ePAjd7wTcDj3vDVuN2y4L3ez4BsoKv3HQs2wHv/M+AF4C/eeJOI21v3ZqBDXFlT+M48A/zQG84CjmsKcdf59aY7gAb4Ip4FvB0zPgWYku64vFi6UD0prANO8oZPAtZ5w08A4+LrAeOAJ2LKq9VrwNfxOm4fV00qfiAPWAqcgXvBUUb8dwb37LmzvOEMr57Ef49i6/kYbydgPu4Fnn/x4mj0ccesazNHJoVG/Z0BWgOb8I6/NpW4v82jOew+SrW7jcbgBFX9CsB7Pt4rT/Ya0v7avN0SA3C3uJtE/N4umGXALuAd3K3lfaoaShBHNEZv+jdA+zTF/r/AfwCON96ephF3hALzRGSJuL0UQOP/zuQDJcDT3m676SLSognEXWfNISmk0t1GY5fsNaT1tYlIS+BV4Cequr+mqgnK0ha/qoZVtT/ulvdgoGcNcTSK2EVkFLBLVZfEFtcQQ6OIO87ZqloIXAj8u4gMraFuY4k/A3c372OqOgAoxd1dlExjibvOmkNS2AbEdrTXCdiRplhqs1O8q7y9511eebLXkLbXJiKZuAnheVV9zStuMvEDqOo+YAHuvt/jRCRy3U5sHNEYveltcC+0bOjYzwbGiMhm3B6H/wW35dDY445S1R3e8y7g/3ATcmP/zmwDtqnq373xV3CTRGOPu86aQ1KotbuNRmQ2EDkrYQLuvvpI+fe9MxvOBL7xmqxvAyNEpK139sMIr8xXIiLAH4E1qvo/TSl+EekoIsd5w7nAebjdq7wHjE0Se+Q1jQX+qu5O4dnA1d5ZPl2BbsAnfsWtqlNUtZOqdsH9Dv9VVa9t7HFHiEgLEWkVGcb9rFfSyL8zqvoPYKuInO4VDQdWN/a4v5V0H9RoiAfuGQGf4+47/n/pjseL6UXgK6AKdyvi33D3+c4H1nvP7by6gnvDoi+AFUBRzHImARu8xw8aKPYhuE3f5cAy73FRU4gfKAA+9WJfCdzllefj/jluAF4Gsr3yHG98gzc9P2ZZ/897TeuACxvwuzOMw2cfNYm4vTg/8x6rIr/DJvKd6Q8Ue9+ZP+OePdTo467rw65oNsYYE9Ucdh8ZY4xJkSUFY4wxUZYUjDHGRFlSMMYYE2VJwRhjTJQlBeMbEVkgIr7fr1ZEbvF6r3w+rry/iFxUh+WdLCKvpFBvbuSah/okIjNEZGwtdSaKyMn1ve76IiLDxOvJ1TQtlhRMoxRzlW4qbgIuUvdirlj9ca+fOKrlq+oOVa3xT9mrd5G6V0Wnw0Sg0SYF03RZUmjmRKSLt5X9pLj3F5jnXelbbUtfRDp4XSxEtlL/LCJviMgmEfmRiPzM6zDsYxFpF7OK8SLyNxFZKSKDvflbiHs/icXePJfELPdlEXkDmJcg1p95y1kpIj/xyh7HvTBqtoj8NKZuFnAPcJW4/fdfJSJ3i8g0EZkH/Ml77R+IyFLv8d2Y92RlTEyvichb4vaD/5uYdWz23pea3sNB4varv0hEfisx98+IWY6IyB9EZLWIzOFw52qIyF3e+7TSi128VkQR8Lz32nIT1Uuwniu86Z+JyMKY15roPRgmIu+LyCwR+VxE7heRa8W9F8UKEfmOV2+GiDzuLeNzcftoil9vss+7t7e8Zd571C1+XpMG6b56zh7pfeB23x0C+nvjs4Dx3vACvCsygQ7AZm94Iu5Vma2Ajrg9cN7gTXsIt4O8yPxPesND8boJB34ds47jcK82b+Etdxve1aFxcQ7EvUK0BdAS96rYAd60zcR1yRwT5x9ixu8GlgC53ngekOMNdwOKY96TlTHL2Ijbd1AOsAXoHLveWt7DlcB3veH7iekqPSauy3B7aw3ibv3vA8Z609rF1HsWGB3/2dRUL249K4BTIu97Le/BMC+Ok3DvvbAd+JU37cfA/3rDM4C3cDcwu3mfXw7Vr7pO9nn/HrjWK8+KfC72SO/DWgoGYJOqLvOGl+D+ydXmPVU9oKoluEnhDa98Rdz8LwKo6kKgtbj74EcAd4jbffUC3D+RU73676jq3gTrGwL8n6qWqupB4DXgn1N7edXMVtUybzgTeFJEVuB2CdEryTzzVfUbVS3H7ffmtAR1jngPvdfaSlX/5pW/kGT5Q4EX1e29dQfw15hp54p757QVuJ3g9U6yjFTqfQTMEJHrcBMQ1PweLFbVr1S1ArfbhkjrLf4znqWqjqqux02gPeLWm+zzXgT8QkRuB06L+VxMGh3Nfltz7KqIGQ4Dud5wiMO7GHNqmMeJGXeo/r2K70cl0o3w5aq6LnaCiJyB2zVxIom6Hq6L2OX/FNgJ9MN9neVJ5ol/fxL9bhK9h0cT8xH9zYhIDvAobotgq4jczZGfQ8r1VPUG7z2+GFgmIv2Bm0n+Hnybz7haiCT4vIE1IvJ3L563ReSHqvpXTFpZS8HUZDPubhs43BPn0boKQESG4PYY+Q1u75A3R/Z7i8iAFJazEPieiOSJ28vmpcAHtcxzAHcXVzJtgK9U1QH+lcNbz/VCVb8GDojbWya4vZsmshC359KguN0wn+uVR/7Yd4t774rYzyD2tdVUL0pEvqOqf1fVu3DvxNaZ+nkPrhCRgHecIR+3o71YCT9vEckHNqrqw7i9ixbUYd2mnllSMDV5ELhRRP6Gu++8Lr725n8ctydYgHtxd1ss9w683lvbQlR1Ke7+609w7/I2XVU/rWW294Be3oHMqxJMfxSYICIfA91J3kr5Nv4NmCYii3C3mL9JUOf/cHvbXAE8BrwP0fs9POmV/xm3G/iIGcDj3i6Zihrqxfqtd5B4JW4i+oz6eQ/WeTG/iXtsKb7FlezzvgpY6b2GHsCfIHqqr51ZlSbWS6oxPhKRlt4xEETkDtz7+v44zWHVGxGZgXtAudbrOkzTYMcUjPHXxSIyBfe3tgX3bCZjGi1rKRhjjImyYwrGGGOiLCkYY4yJsqRgjDEmypKCMcaYKEsKxhhjoiwpGGOMifr/rErHUQoAVaAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax =svm_liner_scores_for_each_size_top.plot(x=\"X_train.shape[0]\",y=\"test_score\")\n",
    "svm_rbf_scores_for_each_size_top.plot(x=\"X_train.shape[0]\",y=\"test_score\",ax=ax)\n",
    "randam_fo_scores_for_each_size_top.plot(x=\"X_train.shape[0]\",y=\"test_score\",ax=ax)\n",
    "logistic_r_scores_for_each_size_top.plot(x=\"X_train.shape[0]\",y=\"test_score\",ax=ax)\n",
    "ax.legend([\"svm linear\", \"svm rbf\", \"randam forest\",\"logistic reg.\"])\n",
    "plt.xlabel(\"number of training data samples.\")\n",
    "plt.ylabel(\"score using test data.\")\n",
    "plt.ylim(.5,1.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_spulit_num</th>\n",
       "      <th>test_size</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>X_train.shape</th>\n",
       "      <th>X_test.shape</th>\n",
       "      <th>X_train.shape[0]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.985690</td>\n",
       "      <td>0.983385</td>\n",
       "      <td>(6499, 8)</td>\n",
       "      <td>(1625, 8)</td>\n",
       "      <td>6499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.983506</td>\n",
       "      <td>0.986952</td>\n",
       "      <td>(4062, 8)</td>\n",
       "      <td>(4062, 8)</td>\n",
       "      <td>4062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.987685</td>\n",
       "      <td>0.984956</td>\n",
       "      <td>(812, 8)</td>\n",
       "      <td>(7312, 8)</td>\n",
       "      <td>812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.982394</td>\n",
       "      <td>0.979089</td>\n",
       "      <td>(568, 8)</td>\n",
       "      <td>(7556, 8)</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.984568</td>\n",
       "      <td>0.985256</td>\n",
       "      <td>(324, 8)</td>\n",
       "      <td>(7800, 8)</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.985180</td>\n",
       "      <td>(162, 8)</td>\n",
       "      <td>(7962, 8)</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.950889</td>\n",
       "      <td>(81, 8)</td>\n",
       "      <td>(8043, 8)</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.747166</td>\n",
       "      <td>(8, 8)</td>\n",
       "      <td>(8116, 8)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  test_spulit_num  test_size  train_score  test_score X_train.shape  \\\n",
       "0               0      0.200     0.985690    0.983385     (6499, 8)   \n",
       "1               0      0.500     0.983506    0.986952     (4062, 8)   \n",
       "2               0      0.900     0.987685    0.984956      (812, 8)   \n",
       "3               0      0.930     0.982394    0.979089      (568, 8)   \n",
       "4               0      0.960     0.984568    0.985256      (324, 8)   \n",
       "5               0      0.980     0.987654    0.985180      (162, 8)   \n",
       "6               0      0.990     0.987654    0.950889       (81, 8)   \n",
       "7               0      0.999     1.000000    0.747166        (8, 8)   \n",
       "\n",
       "  X_test.shape X_train.shape[0]  \n",
       "0    (1625, 8)             6499  \n",
       "1    (4062, 8)             4062  \n",
       "2    (7312, 8)              812  \n",
       "3    (7556, 8)              568  \n",
       "4    (7800, 8)              324  \n",
       "5    (7962, 8)              162  \n",
       "6    (8043, 8)               81  \n",
       "7    (8116, 8)                8  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_liner_scores_for_each_size_top "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_spulit_num</th>\n",
       "      <th>test_size</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>X_train.shape</th>\n",
       "      <th>X_test.shape</th>\n",
       "      <th>X_train.shape[0]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.985690</td>\n",
       "      <td>0.983385</td>\n",
       "      <td>(6499, 8)</td>\n",
       "      <td>(1625, 8)</td>\n",
       "      <td>6499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.983506</td>\n",
       "      <td>0.986952</td>\n",
       "      <td>(4062, 8)</td>\n",
       "      <td>(4062, 8)</td>\n",
       "      <td>4062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.987685</td>\n",
       "      <td>0.984956</td>\n",
       "      <td>(812, 8)</td>\n",
       "      <td>(7312, 8)</td>\n",
       "      <td>812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>0.985177</td>\n",
       "      <td>(568, 8)</td>\n",
       "      <td>(7556, 8)</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.984568</td>\n",
       "      <td>0.985256</td>\n",
       "      <td>(324, 8)</td>\n",
       "      <td>(7800, 8)</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.963075</td>\n",
       "      <td>(162, 8)</td>\n",
       "      <td>(7962, 8)</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.950889</td>\n",
       "      <td>(81, 8)</td>\n",
       "      <td>(8043, 8)</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.747166</td>\n",
       "      <td>(8, 8)</td>\n",
       "      <td>(8116, 8)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  test_spulit_num  test_size  train_score  test_score X_train.shape  \\\n",
       "0               0      0.200     0.985690    0.983385     (6499, 8)   \n",
       "1               0      0.500     0.983506    0.986952     (4062, 8)   \n",
       "2               0      0.900     0.987685    0.984956      (812, 8)   \n",
       "3               0      0.930     0.985915    0.985177      (568, 8)   \n",
       "4               0      0.960     0.984568    0.985256      (324, 8)   \n",
       "5               0      0.980     0.962963    0.963075      (162, 8)   \n",
       "6               0      0.990     0.987654    0.950889       (81, 8)   \n",
       "7               0      0.999     1.000000    0.747166        (8, 8)   \n",
       "\n",
       "  X_test.shape X_train.shape[0]  \n",
       "0    (1625, 8)             6499  \n",
       "1    (4062, 8)             4062  \n",
       "2    (7312, 8)              812  \n",
       "3    (7556, 8)              568  \n",
       "4    (7800, 8)              324  \n",
       "5    (7962, 8)              162  \n",
       "6    (8043, 8)               81  \n",
       "7    (8116, 8)                8  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_rbf_scores_for_each_size_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_spulit_num</th>\n",
       "      <th>test_size</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>X_train.shape</th>\n",
       "      <th>X_test.shape</th>\n",
       "      <th>X_train.shape[0]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.986459</td>\n",
       "      <td>0.985231</td>\n",
       "      <td>(6499, 8)</td>\n",
       "      <td>(1625, 8)</td>\n",
       "      <td>6499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.983998</td>\n",
       "      <td>0.988429</td>\n",
       "      <td>(4062, 8)</td>\n",
       "      <td>(4062, 8)</td>\n",
       "      <td>4062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.990148</td>\n",
       "      <td>0.983589</td>\n",
       "      <td>(812, 8)</td>\n",
       "      <td>(7312, 8)</td>\n",
       "      <td>812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>0.985177</td>\n",
       "      <td>(568, 8)</td>\n",
       "      <td>(7556, 8)</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.984568</td>\n",
       "      <td>0.978077</td>\n",
       "      <td>(324, 8)</td>\n",
       "      <td>(7800, 8)</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.950617</td>\n",
       "      <td>0.951269</td>\n",
       "      <td>(162, 8)</td>\n",
       "      <td>(7962, 8)</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.961333</td>\n",
       "      <td>(81, 8)</td>\n",
       "      <td>(8043, 8)</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.919172</td>\n",
       "      <td>(8, 8)</td>\n",
       "      <td>(8116, 8)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  test_spulit_num  test_size  train_score  test_score X_train.shape  \\\n",
       "0               0      0.200     0.986459    0.985231     (6499, 8)   \n",
       "1               0      0.500     0.983998    0.988429     (4062, 8)   \n",
       "2               0      0.900     0.990148    0.983589      (812, 8)   \n",
       "3               0      0.930     0.985915    0.985177      (568, 8)   \n",
       "4               0      0.960     0.984568    0.978077      (324, 8)   \n",
       "5               0      0.980     0.950617    0.951269      (162, 8)   \n",
       "6               0      0.990     0.987654    0.961333       (81, 8)   \n",
       "7               0      0.999     1.000000    0.919172        (8, 8)   \n",
       "\n",
       "  X_test.shape X_train.shape[0]  \n",
       "0    (1625, 8)             6499  \n",
       "1    (4062, 8)             4062  \n",
       "2    (7312, 8)              812  \n",
       "3    (7556, 8)              568  \n",
       "4    (7800, 8)              324  \n",
       "5    (7962, 8)              162  \n",
       "6    (8043, 8)               81  \n",
       "7    (8116, 8)                8  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randam_fo_scores_for_each_size_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_spulit_num</th>\n",
       "      <th>test_size</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>X_train.shape</th>\n",
       "      <th>X_test.shape</th>\n",
       "      <th>X_train.shape[0]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.974458</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>(6499, 8)</td>\n",
       "      <td>(1625, 8)</td>\n",
       "      <td>6499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.970704</td>\n",
       "      <td>0.976120</td>\n",
       "      <td>(4062, 8)</td>\n",
       "      <td>(4062, 8)</td>\n",
       "      <td>4062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.969212</td>\n",
       "      <td>0.973879</td>\n",
       "      <td>(812, 8)</td>\n",
       "      <td>(7312, 8)</td>\n",
       "      <td>812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.977113</td>\n",
       "      <td>0.973134</td>\n",
       "      <td>(568, 8)</td>\n",
       "      <td>(7556, 8)</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.967692</td>\n",
       "      <td>(324, 8)</td>\n",
       "      <td>(7800, 8)</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.969136</td>\n",
       "      <td>0.967470</td>\n",
       "      <td>(162, 8)</td>\n",
       "      <td>(7962, 8)</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.955365</td>\n",
       "      <td>(81, 8)</td>\n",
       "      <td>(8043, 8)</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899458</td>\n",
       "      <td>(8, 8)</td>\n",
       "      <td>(8116, 8)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  test_spulit_num  test_size  train_score  test_score X_train.shape  \\\n",
       "0               0      0.200     0.974458    0.969231     (6499, 8)   \n",
       "1               0      0.500     0.970704    0.976120     (4062, 8)   \n",
       "2               0      0.900     0.969212    0.973879      (812, 8)   \n",
       "3               0      0.930     0.977113    0.973134      (568, 8)   \n",
       "4               0      0.960     0.962963    0.967692      (324, 8)   \n",
       "5               0      0.980     0.969136    0.967470      (162, 8)   \n",
       "6               0      0.990     0.987654    0.955365       (81, 8)   \n",
       "7               0      0.999     1.000000    0.899458        (8, 8)   \n",
       "\n",
       "  X_test.shape X_train.shape[0]  \n",
       "0    (1625, 8)             6499  \n",
       "1    (4062, 8)             4062  \n",
       "2    (7312, 8)              812  \n",
       "3    (7556, 8)              568  \n",
       "4    (7800, 8)              324  \n",
       "5    (7962, 8)              162  \n",
       "6    (8043, 8)               81  \n",
       "7    (8116, 8)                8  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_r_scores_for_each_size_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importanceが低い説明変数のみを使って、計算をする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8124, 8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data, test dataを作る。\n",
    "y_btm = dfm_d.class_p.to_frame()\n",
    "X_btm = dfm_d.drop([\"class_p\",\"class_e\"], axis=1)\n",
    "X_btm = X_btm.loc[:,importance_btm]\n",
    "\n",
    "X_btm.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm linear::: i,j,best C: 0.2   0   {'C': 5}\n",
      "svm rbf::: i,j,best C: 0.2   0   {'C': 5}\n",
      "randam forest::: i,j,best C: 0.2   0   {'max_depth': 7, 'n_estimators': 10}\n",
      "logistic regression::: i,j,best C: 0.2   0   {'C': 10}\n",
      "svm linear::: i,j,best C: 0.5   0   {'C': 5}\n",
      "svm rbf::: i,j,best C: 0.5   0   {'C': 5}\n",
      "randam forest::: i,j,best C: 0.5   0   {'max_depth': 7, 'n_estimators': 10}\n",
      "logistic regression::: i,j,best C: 0.5   0   {'C': 10}\n",
      "svm linear::: i,j,best C: 0.9   0   {'C': 1}\n",
      "svm rbf::: i,j,best C: 0.9   0   {'C': 1}\n",
      "randam forest::: i,j,best C: 0.9   0   {'max_depth': 7, 'n_estimators': 10}\n",
      "logistic regression::: i,j,best C: 0.9   0   {'C': 1}\n",
      "svm linear::: i,j,best C: 0.93   0   {'C': 1}\n",
      "svm rbf::: i,j,best C: 0.93   0   {'C': 1}\n",
      "randam forest::: i,j,best C: 0.93   0   {'max_depth': 7, 'n_estimators': 10}\n",
      "logistic regression::: i,j,best C: 0.93   0   {'C': 1}\n",
      "svm linear::: i,j,best C: 0.96   0   {'C': 1}\n",
      "svm rbf::: i,j,best C: 0.96   0   {'C': 1}\n",
      "randam forest::: i,j,best C: 0.96   0   {'max_depth': 7, 'n_estimators': 10}\n",
      "logistic regression::: i,j,best C: 0.96   0   {'C': 1}\n",
      "svm linear::: i,j,best C: 0.98   0   {'C': 1}\n",
      "svm rbf::: i,j,best C: 0.98   0   {'C': 10}\n",
      "randam forest::: i,j,best C: 0.98   0   {'max_depth': 7, 'n_estimators': 10}\n",
      "logistic regression::: i,j,best C: 0.98   0   {'C': 1}\n",
      "svm linear::: i,j,best C: 0.99   0   {'C': 1}\n",
      "svm rbf::: i,j,best C: 0.99   0   {'C': 1}\n",
      "randam forest::: i,j,best C: 0.99   0   {'max_depth': 7, 'n_estimators': 10}\n",
      "logistic regression::: i,j,best C: 0.99   0   {'C': 1}\n",
      "svm linear::: i,j,best C: 0.999   0   {'C': 1}\n",
      "svm rbf::: i,j,best C: 0.999   0   {'C': 1}\n",
      "randam forest::: i,j,best C: 0.999   0   {'max_depth': 7, 'n_estimators': 10}\n",
      "logistic regression::: i,j,best C: 0.999   0   {'C': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    " \n",
    "# 初期化\n",
    "svm_liner_scores_for_each_size_btm  = pd.DataFrame(index=[],columns=tmp_columns)\n",
    "svm_rbf_scores_for_each_size_btm    = pd.DataFrame(index=[],columns=tmp_columns)\n",
    "randam_fo_scores_for_each_size_btm  = pd.DataFrame(index=[],columns=tmp_columns)\n",
    "logistic_r_scores_for_each_size_btm = pd.DataFrame(index=[],columns=tmp_columns)\n",
    "\n",
    "for i in test_size_list:\n",
    "    for j in range(test_split_num):\n",
    "        ### Traindata,TestData\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_btm, y_btm, test_size=i)\n",
    "        \n",
    "        ###\n",
    "        ### svm linear start\n",
    "        ###\n",
    "        parameters = {'C':[1, 5, 10]}\n",
    "        model = SVC(kernel=\"linear\")\n",
    "        clf = GridSearchCV(model, parameters, cv=3)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        print(\"svm linear::: i,j,best C:\", i ,\" \" , j ,\" \",clf.best_params_)\n",
    "        train_score = clf.best_estimator_.score(X_train, y_train)\n",
    "        test_score  = clf.best_estimator_.score(X_test , y_test)\n",
    "\n",
    "        tmp_df = pd.Series([j ,i ,train_score,test_score,X_train.shape,X_test.shape, X_train.shape[0]] ,index=tmp_columns)\n",
    "        svm_liner_scores_for_each_size_btm = svm_liner_scores_for_each_size_btm.append(\n",
    "            tmp_df, ignore_index=True)\n",
    "       \n",
    "        \n",
    "        ####\n",
    "        #### svm rbf start\n",
    "        ####\n",
    "        \n",
    "        parameters = {'C':[1, 5, 10]}\n",
    "        model = SVC(kernel=\"rbf\")\n",
    "        clf = GridSearchCV(model, parameters, cv=3)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        print(\"svm rbf::: i,j,best C:\", i ,\" \" , j ,\" \",clf.best_params_)\n",
    "        train_score = clf.best_estimator_.score(X_train, y_train)\n",
    "        test_score  = clf.best_estimator_.score(X_test , y_test)\n",
    "\n",
    "        tmp_df = pd.Series([j ,i ,train_score,test_score,X_train.shape,X_test.shape, X_train.shape[0]] ,index=tmp_columns)\n",
    "       \n",
    "        svm_rbf_scores_for_each_size_btm = svm_rbf_scores_for_each_size_btm.append(\n",
    "            tmp_df, ignore_index=True)\n",
    "\n",
    "        \n",
    "        ####\n",
    "        #### randam forest start\n",
    "        ####        \n",
    "        parameters = {'max_depth':[7,10,12], 'n_estimators':[10]}\n",
    "        model = RandomForestClassifier(min_samples_leaf=2, min_samples_split=2, random_state=1234)\n",
    "        clf = GridSearchCV(model, parameters ,cv=3)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        print(\"randam forest::: i,j,best C:\", i ,\" \" , j ,\" \",clf.best_params_)\n",
    "        train_score = clf.best_estimator_.score(X_train, y_train)\n",
    "        test_score  = clf.best_estimator_.score(X_test , y_test)\n",
    "\n",
    "        tmp_df = pd.Series([j ,i ,train_score,test_score,X_train.shape,X_test.shape, X_train.shape[0]] ,index=tmp_columns)       \n",
    "        randam_fo_scores_for_each_size_btm = randam_fo_scores_for_each_size_btm.append(\n",
    "            tmp_df, ignore_index=True)\n",
    "        \n",
    "        \n",
    "        ####\n",
    "        #### Logistic Regression\n",
    "        ####        \n",
    "        parameters = {'C':[1,5,10]}\n",
    "        model = LogisticRegression()\n",
    "        clf = GridSearchCV(model, parameters ,cv=3)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        print(\"logistic regression::: i,j,best C:\", i ,\" \" , j ,\" \",clf.best_params_)\n",
    "        train_score = clf.best_estimator_.score(X_train, y_train)\n",
    "        test_score  = clf.best_estimator_.score(X_test , y_test)\n",
    "\n",
    "        tmp_df = pd.Series([j ,i ,train_score,test_score,X_train.shape,X_test.shape, X_train.shape[0]] ,index=tmp_columns)       \n",
    "        logistic_r_scores_for_each_size_btm = logistic_r_scores_for_each_size_btm.append(\n",
    "            tmp_df, ignore_index=True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 1.05)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax =svm_liner_scores_for_each_size_btm.plot(x=\"X_train.shape[0]\",y=\"test_score\")\n",
    "svm_rbf_scores_for_each_size_btm.plot(x=\"X_train.shape[0]\",y=\"test_score\",ax=ax)\n",
    "randam_fo_scores_for_each_size_btm.plot(x=\"X_train.shape[0]\",y=\"test_score\",ax=ax)\n",
    "logistic_r_scores_for_each_size_btm.plot(x=\"X_train.shape[0]\",y=\"test_score\",ax=ax)\n",
    "ax.legend([\"svm linear\", \"svm rbf\", \"randam forest\",\"logistic reg.\"])\n",
    "plt.xlabel(\"number of training data samples.\")\n",
    "plt.ylabel(\"score using test data.\")\n",
    "plt.ylim(.5,1.05)\n",
    "## 説明変数を下から選ぶとスコアは0.6程度まで落ちる。二択問題なので下限は0.5。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
